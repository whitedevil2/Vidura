{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\home\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import gensim \n",
    "import logging\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown\n",
    "from itertools import product\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"dataset/rajyasabha_questions_and_answers_2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title No 1\n",
      "\n",
      "SPURT IN PRICES OF GOLD .\n",
      "\n",
      "Title No 2\n",
      "\n",
      "OPENING OF TRADE CENTRES IN LATIN AMERICAN COUNTRIES .\n",
      "\n",
      "Title No 3\n",
      "\n",
      "EARLY EXIT OF CHINESE BUSINESSMEN FROM TRADE FAIR .\n",
      "\n",
      "Title No 4\n",
      "\n",
      "DONATION BY STC AND MMTC TO STUDENT WINGS OF POLITICAL PARTIES .\n",
      "\n",
      "Title No 5\n",
      "\n",
      "ENVISAGED EXPORT EARNING TARGETS .\n",
      "\n",
      "Title No 6\n",
      "\n",
      "REQUESTS FOR DENOTIFYING APPROVED SEZS .\n",
      "\n",
      "Title No 7\n",
      "\n",
      "TRADE BETWEEN INDIA AND RUSSIA .\n",
      "\n",
      "Title No 8\n",
      "\n",
      "SEZS IN MAHARASHTRA .\n",
      "\n",
      "Title No 9\n",
      "\n",
      "DONATION BY STC MMTC TO NSUI .\n",
      "\n",
      "Title No 10\n",
      "\n",
      "ANTI DUMPING CASES REGISTERED BY DGAD .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles=data['question_title']\n",
    "for i in range(10):\n",
    "    print('Title No '+str(i+1)+'\\n')\n",
    "    print(titles[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.2\n",
    "BETA = 0.45\n",
    "ETA = 0.4\n",
    "PHI = 0.2\n",
    "DELTA = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_synset_pair(word_1, word_2):\n",
    "    \n",
    "    max_sim = -1.0\n",
    "    synsets_1 = wn.synsets(word_1)\n",
    "    synsets_2 = wn.synsets(word_2)\n",
    "    if len(synsets_1) == 0 or len(synsets_2) == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        max_sim = -1.0\n",
    "        best_pair = None, None\n",
    "        for synset_1 in synsets_1:\n",
    "            for synset_2 in synsets_2:\n",
    "               sim = wn.path_similarity(synset_1, synset_2)\n",
    "               if sim!=None and sim > max_sim:\n",
    "                   max_sim = sim\n",
    "                   best_pair = synset_1, synset_2\n",
    "        return best_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_dist(synset_1, synset_2):\n",
    "    \n",
    "    l_dist = sys.maxsize\n",
    "    if synset_1 is None or synset_2 is None: \n",
    "        return 0.0\n",
    "    if synset_1 == synset_2:\n",
    "        # if synset_1 and synset_2 are the same synset return 0\n",
    "        l_dist = 0.0\n",
    "    else:\n",
    "        wset_1 = set([str(x.name()) for x in synset_1.lemmas()])        \n",
    "        wset_2 = set([str(x.name()) for x in synset_2.lemmas()])\n",
    "        if len(wset_1.intersection(wset_2)) > 0:\n",
    "            # if synset_1 != synset_2 but there is word overlap, return 1.0\n",
    "            l_dist = 1.0\n",
    "        else:\n",
    "            # just compute the shortest path between the two\n",
    "            l_dist = synset_1.shortest_path_distance(synset_2)\n",
    "            if l_dist is None:\n",
    "                l_dist = 0.0\n",
    "    # normalize path length to the range [0,1]\n",
    "    return math.exp(-ALPHA * l_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_dist(synset_1, synset_2):\n",
    "    \n",
    "    h_dist = sys.maxsize\n",
    "    if synset_1 is None or synset_2 is None: \n",
    "        return h_dist\n",
    "    if synset_1 == synset_2:\n",
    "        # return the depth of one of synset_1 or synset_2\n",
    "        h_dist = max([x[1] for x in synset_1.hypernym_distances()])\n",
    "    else:\n",
    "        # find the max depth of least common subsumer\n",
    "        hypernyms_1 = {x[0]:x[1] for x in synset_1.hypernym_distances()}\n",
    "        hypernyms_2 = {x[0]:x[1] for x in synset_2.hypernym_distances()}\n",
    "        lcs_candidates = set(hypernyms_1.keys()).intersection(\n",
    "            set(hypernyms_2.keys()))\n",
    "        if len(lcs_candidates) > 0:\n",
    "            lcs_dists = []\n",
    "            for lcs_candidate in lcs_candidates:\n",
    "                lcs_d1 = 0\n",
    "                if lcs_candidate in hypernyms_1:\n",
    "                    lcs_d1 = hypernyms_1[lcs_candidate]\n",
    "                lcs_d2 = 0\n",
    "                if lcs_candidate in hypernyms_2:\n",
    "                    lcs_d2 = hypernyms_2[lcs_candidate]\n",
    "                lcs_dists.append(max([lcs_d1, lcs_d2]))\n",
    "            h_dist = max(lcs_dists)\n",
    "        else:\n",
    "            h_dist = 0\n",
    "    return ((math.exp(BETA * h_dist) - math.exp(-BETA * h_dist)) / \n",
    "        (math.exp(BETA * h_dist) + math.exp(-BETA * h_dist)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(word_1, word_2):\n",
    "    synset_pair = get_best_synset_pair(word_1, word_2)\n",
    "    return (length_dist(synset_pair[0], synset_pair[1]) * \n",
    "        hierarchy_dist(synset_pair[0], synset_pair[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_word(word, word_set):\n",
    "    max_sim = -1.0\n",
    "    sim_word = \"\"\n",
    "    for ref_word in word_set:\n",
    "      sim = word_similarity(word, ref_word)\n",
    "      if sim > max_sim:\n",
    "          max_sim = sim\n",
    "          sim_word = ref_word\n",
    "    return sim_word, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_freqs = dict()\n",
    "N=0\n",
    "def info_content(lookup_word):\n",
    "    \n",
    "    global N\n",
    "    if N == 0:\n",
    "        # poor man's lazy evaluation\n",
    "        for sent in brown.sents():\n",
    "            for word in sent:\n",
    "                word = word.lower()\n",
    "                if word not in brown_freqs:\n",
    "                    brown_freqs[word] = 0\n",
    "                brown_freqs[word] = brown_freqs[word] + 1\n",
    "                N = N + 1\n",
    "    lookup_word = lookup_word.lower()\n",
    "    n = 0 if lookup_word not in brown_freqs else brown_freqs[lookup_word]\n",
    "    return 1.0 - (math.log(n + 1) / math.log(N + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_vector(words, joint_words, info_content_norm):\n",
    "    sent_set = set(words)\n",
    "    semvec = np.zeros(len(joint_words))\n",
    "    i = 0\n",
    "    for joint_word in joint_words:\n",
    "        if joint_word in sent_set:\n",
    "            # if word in union exists in the sentence, s(i) = 1 (unnormalized)\n",
    "            semvec[i] = 1.0\n",
    "            if info_content_norm:\n",
    "                semvec[i] = semvec[i] * math.pow(info_content(joint_word), 2)\n",
    "        else:\n",
    "            # find the most similar word in the joint set and set the sim value\n",
    "            sim_word, max_sim = most_similar_word(joint_word, sent_set)\n",
    "            semvec[i] = PHI if max_sim > PHI else 0.0\n",
    "            if info_content_norm:\n",
    "                semvec[i] = semvec[i] * info_content(joint_word) * info_content(sim_word)\n",
    "        i = i + 1\n",
    "    return semvec       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD = re.compile(r\"\\w+\")\n",
    "\n",
    "def get_cosine(sentence_1, sentence_2):\n",
    "    sentence_1 = re.sub('[^A-Za-z0-9\\s]', '', sentence_1).lower()\n",
    "    sentence_2 = re.sub('[^A-Za-z0-9\\s]', '', sentence_2).lower()\n",
    "    info_content_norm = True\n",
    "    words_1 = nltk.word_tokenize(sentence_1)\n",
    "    words_2 = nltk.word_tokenize(sentence_2)\n",
    "    joint_words = set(words_1).union(set(words_2))\n",
    "    vec_1 = semantic_vector(words_1, joint_words, info_content_norm)\n",
    "    vec_2 = semantic_vector(words_2, joint_words, info_content_norm)\n",
    "    return np.dot(vec_1, vec_2.T) / (np.linalg.norm(vec_1) * np.linalg.norm(vec_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine: 0.9497113451849513\n"
     ]
    }
   ],
   "source": [
    "text1 = \"This is a foo bar sentence .\"\n",
    "text2 = \"This sentence is similar to a foo bar sentence .\"\n",
    "\n",
    "#vector1 = text_to_vector(text1)\n",
    "#vector2 = text_to_vector(text2)\n",
    "\n",
    "cosine = get_cosine(text1, text2)\n",
    "\n",
    "print(\"Cosine:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_indices(query,title_list):\n",
    "    \n",
    "    cosine_list=np.empty(len(title_list))\n",
    "    for i in range(len(title_list)):\n",
    "        cosine_val_i=get_cosine(query,title_list[i])\n",
    "        cosine_list[i]=cosine_val_i\n",
    "    \n",
    "    relevant_indices=cosine_list.argsort()[-10:][::-1]\n",
    "    return relevant_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_titles(query):\n",
    "    titles=data['question_title'].values.tolist()\n",
    "    relevant_indices=get_relevant_indices(query,titles)\n",
    "    relevant_titles=[]\n",
    "    for i in range(len(relevant_indices)):\n",
    "        relevant_titles.append(titles[relevant_indices[i]])\n",
    "    \n",
    "    relevant_titles_df=pd.DataFrame({'Indices':relevant_indices,\n",
    "                                    'Titles':relevant_titles})\n",
    "    return relevant_titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Indices                                             Titles\n",
      "0        7                              SEZS IN MAHARASHTRA .\n",
      "1       98               PROBLEMS OF FARMERS OF MAHARASHTRA .\n",
      "2       14          EXTENSION OF TIME TO DEVELOPERS OF SEZS .\n",
      "3       16  SEZS CONVERTED INTO COMMERCIAL REAL ESTATE OPE...\n",
      "4        5           REQUESTS FOR DENOTIFYING APPROVED SEZS .\n",
      "5      171             IMPROVEMENT OF ROAD NETWORK IN GUJARAT\n",
      "6      161                      SETTING UP OF FAMILY COURTS .\n",
      "7      240                    SETTING UP OF FAST TRACK COURTS\n",
      "8       55                           PRICE VARIATION OF DRUGS\n",
      "9      199  . OPENING OF RETAIL CENTRES BY CORPORATE HOUSE...\n",
      "\n",
      "\n",
      " For better visualization\n",
      "\n",
      "\n",
      "Relevant Indices: \n",
      "\n",
      "[  7  98  14  16   5 171 161 240  55 199]\n",
      "\n",
      "Relevant Titles:\n",
      "\n",
      "['SEZS IN MAHARASHTRA .' 'PROBLEMS OF FARMERS OF MAHARASHTRA .'\n",
      " 'EXTENSION OF TIME TO DEVELOPERS OF SEZS .'\n",
      " 'SEZS CONVERTED INTO COMMERCIAL REAL ESTATE OPERATIONS .'\n",
      " 'REQUESTS FOR DENOTIFYING APPROVED SEZS .'\n",
      " 'IMPROVEMENT OF ROAD NETWORK IN GUJARAT' 'SETTING UP OF FAMILY COURTS .'\n",
      " 'SETTING UP OF FAST TRACK COURTS' 'PRICE VARIATION OF DRUGS'\n",
      " '. OPENING OF RETAIL CENTRES BY CORPORATE HOUSES IN SMALL CITIES .']\n"
     ]
    }
   ],
   "source": [
    "relevant_titles=get_relevant_titles(\"SEZS IN MAHARASHTRA\")\n",
    "print(relevant_titles)\n",
    "\n",
    "print('\\n\\n For better visualization')\n",
    "print('\\n\\nRelevant Indices: \\n')\n",
    "print(relevant_titles['Indices'].values)\n",
    "\n",
    "print('\\nRelevant Titles:\\n')\n",
    "print(relevant_titles['Titles'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
